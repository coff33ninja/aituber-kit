[
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "TTFont",
        "importPath": "fontTools.ttLib",
        "description": "fontTools.ttLib",
        "isExtraImport": true,
        "detail": "fontTools.ttLib",
        "documentation": {}
    },
    {
        "label": "sfnt",
        "importPath": "fontTools.ttLib",
        "description": "fontTools.ttLib",
        "isExtraImport": true,
        "detail": "fontTools.ttLib",
        "documentation": {}
    },
    {
        "label": "TTFont",
        "importPath": "fontTools.ttLib",
        "description": "fontTools.ttLib",
        "isExtraImport": true,
        "detail": "fontTools.ttLib",
        "documentation": {}
    },
    {
        "label": "timestampNow",
        "importPath": "fontTools.misc.timeTools",
        "description": "fontTools.misc.timeTools",
        "isExtraImport": true,
        "detail": "fontTools.misc.timeTools",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "parse_tfm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "parse_tfm",
        "description": "parse_tfm",
        "detail": "parse_tfm",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "Anthropic",
        "importPath": "anthropic",
        "description": "anthropic",
        "isExtraImport": true,
        "detail": "anthropic",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain_openai",
        "description": "langchain_openai",
        "isExtraImport": true,
        "detail": "langchain_openai",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "node_modules.flatted.python.flatted",
        "description": "node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "sfnt.USE_ZOPFLI",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "sfnt.USE_ZOPFLI = True\nif len(sys.argv) < 2:\n    print(\"Usage: %s <font file>\" % sys.argv[0])\n    sys.exit(1)\nfont_file = sys.argv[1]\nfont_name = os.path.splitext(os.path.basename(font_file))[0]\nfont = TTFont(font_file, recalcBBoxes=False, recalcTimestamp=False)\n# fix timestamp to the epoch\nfont['head'].created = 0\nfont['head'].modified = 0",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font_file",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font_file = sys.argv[1]\nfont_name = os.path.splitext(os.path.basename(font_file))[0]\nfont = TTFont(font_file, recalcBBoxes=False, recalcTimestamp=False)\n# fix timestamp to the epoch\nfont['head'].created = 0\nfont['head'].modified = 0\n# remove fontforge timestamps\nif 'FFTM' in font:\n    del font['FFTM']\n# remove redundant GDEF table",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font_name",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font_name = os.path.splitext(os.path.basename(font_file))[0]\nfont = TTFont(font_file, recalcBBoxes=False, recalcTimestamp=False)\n# fix timestamp to the epoch\nfont['head'].created = 0\nfont['head'].modified = 0\n# remove fontforge timestamps\nif 'FFTM' in font:\n    del font['FFTM']\n# remove redundant GDEF table\nif 'GDEF' in font:",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font = TTFont(font_file, recalcBBoxes=False, recalcTimestamp=False)\n# fix timestamp to the epoch\nfont['head'].created = 0\nfont['head'].modified = 0\n# remove fontforge timestamps\nif 'FFTM' in font:\n    del font['FFTM']\n# remove redundant GDEF table\nif 'GDEF' in font:\n    del font['GDEF']",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['head'].created",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['head'].created = 0\nfont['head'].modified = 0\n# remove fontforge timestamps\nif 'FFTM' in font:\n    del font['FFTM']\n# remove redundant GDEF table\nif 'GDEF' in font:\n    del font['GDEF']\n# remove Macintosh table\n# https://developer.apple.com/fonts/TrueType-Reference-Manual/RM06/Chap6cmap.html",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['head'].modified",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['head'].modified = 0\n# remove fontforge timestamps\nif 'FFTM' in font:\n    del font['FFTM']\n# remove redundant GDEF table\nif 'GDEF' in font:\n    del font['GDEF']\n# remove Macintosh table\n# https://developer.apple.com/fonts/TrueType-Reference-Manual/RM06/Chap6cmap.html\nfont['name'].names = [record for record in font['name'].names if record.platformID != 1]",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['name'].names",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['name'].names = [record for record in font['name'].names if record.platformID != 1]\nfont['cmap'].tables = [table for table in font['cmap'].tables if table.platformID != 1]\n# fix OS/2 and hhea metrics\nglyf = font['glyf']\nascent = int(max(glyf[c].yMax for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMax\")))\ndescent = -int(min(glyf[c].yMin for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMin\")))\nfont['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['cmap'].tables",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['cmap'].tables = [table for table in font['cmap'].tables if table.platformID != 1]\n# fix OS/2 and hhea metrics\nglyf = font['glyf']\nascent = int(max(glyf[c].yMax for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMax\")))\ndescent = -int(min(glyf[c].yMin for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMin\")))\nfont['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "glyf",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "glyf = font['glyf']\nascent = int(max(glyf[c].yMax for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMax\")))\ndescent = -int(min(glyf[c].yMin for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMin\")))\nfont['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "ascent",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "ascent = int(max(glyf[c].yMax for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMax\")))\ndescent = -int(min(glyf[c].yMin for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMin\")))\nfont['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "descent",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "descent = -int(min(glyf[c].yMin for c in font.getGlyphOrder() if hasattr(glyf[c], \"yMin\")))\nfont['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['OS/2'].usWinAscent",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['OS/2'].usWinAscent = ascent\nfont['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)\n# save WOFF2",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['OS/2'].usWinDescent",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['OS/2'].usWinDescent = descent\nfont['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)\n# save WOFF2\nfont.flavor = 'woff2'",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['hhea'].ascent",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['hhea'].ascent = ascent\nfont['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)\n# save WOFF2\nfont.flavor = 'woff2'\nfont.save(os.path.join('woff2', font_name + '.woff2'), reorderTables=None)",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font['hhea'].descent",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font['hhea'].descent = -descent\n# save TTF\nfont.save(font_file, reorderTables=None)\n# save WOFF\nfont.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)\n# save WOFF2\nfont.flavor = 'woff2'\nfont.save(os.path.join('woff2', font_name + '.woff2'), reorderTables=None)",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font.flavor",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font.flavor = 'woff'\nfont.save(os.path.join('woff', font_name + '.woff'), reorderTables=None)\n# save WOFF2\nfont.flavor = 'woff2'\nfont.save(os.path.join('woff2', font_name + '.woff2'), reorderTables=None)",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "font.flavor",
        "kind": 5,
        "importPath": "node_modules.katex.src.fonts.generate_fonts",
        "description": "node_modules.katex.src.fonts.generate_fonts",
        "peekOfCode": "font.flavor = 'woff2'\nfont.save(os.path.join('woff2', font_name + '.woff2'), reorderTables=None)",
        "detail": "node_modules.katex.src.fonts.generate_fonts",
        "documentation": {}
    },
    {
        "label": "find_font_path",
        "kind": 2,
        "importPath": "node_modules.katex.src.metrics.extract_tfms",
        "description": "node_modules.katex.src.metrics.extract_tfms",
        "peekOfCode": "def find_font_path(font_name):\n    try:\n        font_path = subprocess.check_output(['kpsewhich', font_name])\n    except OSError:\n        raise RuntimeError(\"Couldn't find kpsewhich program, make sure you\" +\n                           \" have TeX installed\")\n    except subprocess.CalledProcessError:\n        raise RuntimeError(\"Couldn't find font metrics: '%s'\" % font_name)\n    return font_path.strip()\ndef main():",
        "detail": "node_modules.katex.src.metrics.extract_tfms",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "node_modules.katex.src.metrics.extract_tfms",
        "description": "node_modules.katex.src.metrics.extract_tfms",
        "peekOfCode": "def main():\n    mapping = json.load(sys.stdin)\n    fonts = [\n        'cmbsy10.tfm',\n        'cmbx10.tfm',\n        'cmbxti10.tfm',\n        'cmex10.tfm',\n        'cmmi10.tfm',\n        'cmmib10.tfm',\n        'cmr10.tfm',",
        "detail": "node_modules.katex.src.metrics.extract_tfms",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "node_modules.katex.src.metrics.extract_ttfs",
        "description": "node_modules.katex.src.metrics.extract_ttfs",
        "peekOfCode": "def main():\n    start_json = json.load(sys.stdin)\n    for font in start_json:\n        fontInfo = TTFont(\"../../fonts/KaTeX_\" + font + \".ttf\")\n        glyf = fontInfo[\"glyf\"]\n        widths = fontInfo.getGlyphSet()\n        unitsPerEm = float(fontInfo[\"head\"].unitsPerEm)\n        # We keep ALL Unicode cmaps, not just fontInfo[\"cmap\"].getcmap(3, 1).\n        # This is playing it extra safe, since it reports inconsistencies.\n        # Platform 0 is Unicode, platform 3 is Windows. For platform 3,",
        "detail": "node_modules.katex.src.metrics.extract_ttfs",
        "documentation": {}
    },
    {
        "label": "metrics_to_extract",
        "kind": 5,
        "importPath": "node_modules.katex.src.metrics.extract_ttfs",
        "description": "node_modules.katex.src.metrics.extract_ttfs",
        "peekOfCode": "metrics_to_extract = {\n    # Font name\n    \"AMS-Regular\": {\n        u\"\\u21e2\": None,  # \\dashrightarrow\n        u\"\\u21e0\": None,  # \\dashleftarrow\n    },\n    \"Main-Regular\": {\n        # Skew and italic metrics can't be easily parsed from the TTF. Instead,\n        # we map each character to a \"base character\", which is a character\n        # from the same font with correct italic and skew metrics. A character",
        "detail": "node_modules.katex.src.metrics.extract_ttfs",
        "documentation": {}
    },
    {
        "label": "props",
        "kind": 5,
        "importPath": "node_modules.katex.src.metrics.format_json",
        "description": "node_modules.katex.src.metrics.format_json",
        "peekOfCode": "props = ['depth', 'height', 'italic', 'skew']\nif len(sys.argv) > 1:\n    if sys.argv[1] == '--width':\n        props.append('width')\ndata = json.load(sys.stdin)\nsys.stdout.write(\n  \"// This file is GENERATED by buildMetrics.sh. DO NOT MODIFY.\\n\")\nsep = \"export default {\\n    \"\nfor font in sorted(data):\n    sys.stdout.write(sep + json.dumps(font))",
        "detail": "node_modules.katex.src.metrics.format_json",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "node_modules.katex.src.metrics.format_json",
        "description": "node_modules.katex.src.metrics.format_json",
        "peekOfCode": "data = json.load(sys.stdin)\nsys.stdout.write(\n  \"// This file is GENERATED by buildMetrics.sh. DO NOT MODIFY.\\n\")\nsep = \"export default {\\n    \"\nfor font in sorted(data):\n    sys.stdout.write(sep + json.dumps(font))\n    sep = \": {\\n        \"\n    for glyph in sorted(data[font], key=int):\n        sys.stdout.write(sep + json.dumps(glyph) + \": \")\n        values = [value if value != 0.0 else 0 for value in",
        "detail": "node_modules.katex.src.metrics.format_json",
        "documentation": {}
    },
    {
        "label": "sep",
        "kind": 5,
        "importPath": "node_modules.katex.src.metrics.format_json",
        "description": "node_modules.katex.src.metrics.format_json",
        "peekOfCode": "sep = \"export default {\\n    \"\nfor font in sorted(data):\n    sys.stdout.write(sep + json.dumps(font))\n    sep = \": {\\n        \"\n    for glyph in sorted(data[font], key=int):\n        sys.stdout.write(sep + json.dumps(glyph) + \": \")\n        values = [value if value != 0.0 else 0 for value in\n                  [data[font][glyph][key] for key in props]]\n        sys.stdout.write(json.dumps(values))\n        sep = \",\\n        \"",
        "detail": "node_modules.katex.src.metrics.format_json",
        "documentation": {}
    },
    {
        "label": "CharInfoWord",
        "kind": 6,
        "importPath": "node_modules.katex.src.metrics.parse_tfm",
        "description": "node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "class CharInfoWord(object):\n    def __init__(self, word):\n        b1, b2, b3, b4 = (word >> 24,\n                          (word & 0xff0000) >> 16,\n                          (word & 0xff00) >> 8,\n                          word & 0xff)\n        self.width_index = b1\n        self.height_index = b2 >> 4\n        self.depth_index = b2 & 0x0f\n        self.italic_index = (b3 & 0b11111100) >> 2",
        "detail": "node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "LigKernProgram",
        "kind": 6,
        "importPath": "node_modules.katex.src.metrics.parse_tfm",
        "description": "node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "class LigKernProgram(object):\n    def __init__(self, program):\n        self.program = program\n    def execute(self, start, next_char):\n        curr_instruction = start\n        while True:\n            instruction = self.program[curr_instruction]\n            (skip, inst_next_char, op, remainder) = instruction\n            if inst_next_char == next_char:\n                if op < 128:",
        "detail": "node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "TfmCharMetrics",
        "kind": 6,
        "importPath": "node_modules.katex.src.metrics.parse_tfm",
        "description": "node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "class TfmCharMetrics(object):\n    def __init__(self, width, height, depth, italic, kern_table):\n        self.width = width\n        self.height = height\n        self.depth = depth\n        self.italic_correction = italic\n        self.kern_table = kern_table\nclass TfmFile(object):\n    def __init__(self, start_char, end_char, char_info, width_table,\n                 height_table, depth_table, italic_table, ligkern_table,",
        "detail": "node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "TfmFile",
        "kind": 6,
        "importPath": "node_modules.katex.src.metrics.parse_tfm",
        "description": "node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "class TfmFile(object):\n    def __init__(self, start_char, end_char, char_info, width_table,\n                 height_table, depth_table, italic_table, ligkern_table,\n                 kern_table):\n        self.start_char = start_char\n        self.end_char = end_char\n        self.char_info = char_info\n        self.width_table = width_table\n        self.height_table = height_table\n        self.depth_table = depth_table",
        "detail": "node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "TfmReader",
        "kind": 6,
        "importPath": "node_modules.katex.src.metrics.parse_tfm",
        "description": "node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "class TfmReader(object):\n    def __init__(self, f):\n        self.f = f\n    def read_byte(self):\n        return ord(self.f.read(1))\n    def read_halfword(self):\n        b1 = self.read_byte()\n        b2 = self.read_byte()\n        return (b1 << 8) | b2\n    def read_word(self):",
        "detail": "node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "read_tfm_file",
        "kind": 2,
        "importPath": "node_modules.katex.src.metrics.parse_tfm",
        "description": "node_modules.katex.src.metrics.parse_tfm",
        "peekOfCode": "def read_tfm_file(file_name):\n    with open(file_name, 'rb') as f:\n        reader = TfmReader(f)\n        # file_size\n        reader.read_halfword()\n        header_size = reader.read_halfword()\n        start_char = reader.read_halfword()\n        end_char = reader.read_halfword()\n        width_table_size = reader.read_halfword()\n        height_table_size = reader.read_halfword()",
        "detail": "node_modules.katex.src.metrics.parse_tfm",
        "documentation": {}
    },
    {
        "label": "GITHUB_API_BASE",
        "kind": 5,
        "importPath": "scripts.analyze_issue",
        "description": "scripts.analyze_issue",
        "peekOfCode": "GITHUB_API_BASE = \"https://api.github.com\"\n# 環境変数から認証情報を取得\nGITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\nif not GITHUB_TOKEN:\n    raise ValueError(\"環境変数 'GITHUB_TOKEN' が設定されていません。\")\nANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\nif not ANTHROPIC_API_KEY:\n    raise ValueError(\"環境変数 'ANTHROPIC_API_KEY' が設定されていません。\")\n# GitHubイベントの情報を取得\nif \"GITHUB_EVENT_PATH\" in os.environ:",
        "detail": "scripts.analyze_issue",
        "documentation": {}
    },
    {
        "label": "GITHUB_TOKEN",
        "kind": 5,
        "importPath": "scripts.analyze_issue",
        "description": "scripts.analyze_issue",
        "peekOfCode": "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\nif not GITHUB_TOKEN:\n    raise ValueError(\"環境変数 'GITHUB_TOKEN' が設定されていません。\")\nANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\nif not ANTHROPIC_API_KEY:\n    raise ValueError(\"環境変数 'ANTHROPIC_API_KEY' が設定されていません。\")\n# GitHubイベントの情報を取得\nif \"GITHUB_EVENT_PATH\" in os.environ:\n    with open(os.environ[\"GITHUB_EVENT_PATH\"]) as event_file:\n        github_event = json.load(event_file)",
        "detail": "scripts.analyze_issue",
        "documentation": {}
    },
    {
        "label": "ANTHROPIC_API_KEY",
        "kind": 5,
        "importPath": "scripts.analyze_issue",
        "description": "scripts.analyze_issue",
        "peekOfCode": "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\nif not ANTHROPIC_API_KEY:\n    raise ValueError(\"環境変数 'ANTHROPIC_API_KEY' が設定されていません。\")\n# GitHubイベントの情報を取得\nif \"GITHUB_EVENT_PATH\" in os.environ:\n    with open(os.environ[\"GITHUB_EVENT_PATH\"]) as event_file:\n        github_event = json.load(event_file)\n    if \"issue\" in github_event:\n        issue_number = github_event[\"issue\"][\"number\"]\n        issue_title = github_event[\"issue\"][\"title\"]",
        "detail": "scripts.analyze_issue",
        "documentation": {}
    },
    {
        "label": "anthropic",
        "kind": 5,
        "importPath": "scripts.analyze_issue",
        "description": "scripts.analyze_issue",
        "peekOfCode": "anthropic = Anthropic(api_key=ANTHROPIC_API_KEY)\n# GitHub API用のヘッダーを定義\nheaders = {\n    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n    \"Accept\": \"application/vnd.github.v3+json\",\n}\n# 関連ファイルを特定するためのClaude API呼び出し\ntry:\n    response = anthropic.messages.create(\n        model=\"claude-3-5-sonnet-20240620\",",
        "detail": "scripts.analyze_issue",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "scripts.analyze_issue",
        "description": "scripts.analyze_issue",
        "peekOfCode": "headers = {\n    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n    \"Accept\": \"application/vnd.github.v3+json\",\n}\n# 関連ファイルを特定するためのClaude API呼び出し\ntry:\n    response = anthropic.messages.create(\n        model=\"claude-3-5-sonnet-20240620\",\n        max_tokens=2048,\n        messages=[",
        "detail": "scripts.analyze_issue",
        "documentation": {}
    },
    {
        "label": "file_contents",
        "kind": 5,
        "importPath": "scripts.analyze_issue",
        "description": "scripts.analyze_issue",
        "peekOfCode": "file_contents = {}\nfor file_info in analysis_result:\n    file_path = file_info[\"file_path\"]\n    file_url = f\"{GITHUB_API_BASE}/repos/{repo_full_name}/contents/{file_path}\"\n    file_response = requests.get(file_url, headers=headers)\n    if file_response.status_code == 200:\n        file_content = file_response.json()[\"content\"]\n        decoded_content = base64.b64decode(file_content).decode(\"utf-8\")\n        file_contents[\n            file_path",
        "detail": "scripts.analyze_issue",
        "documentation": {}
    },
    {
        "label": "comment_url",
        "kind": 5,
        "importPath": "scripts.analyze_issue",
        "description": "scripts.analyze_issue",
        "peekOfCode": "comment_url = f\"{GITHUB_API_BASE}/repos/{repo_full_name}/issues/{issue_number}/comments\"\ncomment_data = {\n    \"body\": f\"## Issue分析結果:\\n\\n```json\\n{json.dumps(analysis_result, indent=2, ensure_ascii=False)}\\n```\\n\\n## コード改善案:\\n\\n{improvement_result}\"\n}\nresponse = requests.post(comment_url, headers=headers, json=comment_data)\nif response.status_code == 201:\n    print(\"分析結果とコード改善案をIssueにコメントとして追加しました。\")\nelse:\n    print(f\"コメントの追加に失敗しました。ステータスコード: {response.status_code}\")\n    print(response.text)",
        "detail": "scripts.analyze_issue",
        "documentation": {}
    },
    {
        "label": "comment_data",
        "kind": 5,
        "importPath": "scripts.analyze_issue",
        "description": "scripts.analyze_issue",
        "peekOfCode": "comment_data = {\n    \"body\": f\"## Issue分析結果:\\n\\n```json\\n{json.dumps(analysis_result, indent=2, ensure_ascii=False)}\\n```\\n\\n## コード改善案:\\n\\n{improvement_result}\"\n}\nresponse = requests.post(comment_url, headers=headers, json=comment_data)\nif response.status_code == 201:\n    print(\"分析結果とコード改善案をIssueにコメントとして追加しました。\")\nelse:\n    print(f\"コメントの追加に失敗しました。ステータスコード: {response.status_code}\")\n    print(response.text)",
        "detail": "scripts.analyze_issue",
        "documentation": {}
    },
    {
        "label": "response",
        "kind": 5,
        "importPath": "scripts.analyze_issue",
        "description": "scripts.analyze_issue",
        "peekOfCode": "response = requests.post(comment_url, headers=headers, json=comment_data)\nif response.status_code == 201:\n    print(\"分析結果とコード改善案をIssueにコメントとして追加しました。\")\nelse:\n    print(f\"コメントの追加に失敗しました。ステータスコード: {response.status_code}\")\n    print(response.text)",
        "detail": "scripts.analyze_issue",
        "documentation": {}
    },
    {
        "label": "get_llm",
        "kind": 2,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "def get_llm():\n    \"\"\"LLMインスタンスを取得する\"\"\"\n    return ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0, api_key=OPENAI_API_KEY)\n# --- GitHub API 関数 ---\ndef get_file_content(file_path: str, ref: Optional[str] = None) -> Optional[str]:\n    \"\"\"指定されたファイルの内容を取得する\"\"\"\n    url = f\"{GITHUB_API_BASE}/repos/{REPO_FULL_NAME}/contents/{file_path}\"\n    params = {}\n    if ref:\n        params[\"ref\"] = ref",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "get_file_content",
        "kind": 2,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "def get_file_content(file_path: str, ref: Optional[str] = None) -> Optional[str]:\n    \"\"\"指定されたファイルの内容を取得する\"\"\"\n    url = f\"{GITHUB_API_BASE}/repos/{REPO_FULL_NAME}/contents/{file_path}\"\n    params = {}\n    if ref:\n        params[\"ref\"] = ref\n    try:\n        response = requests.get(url, headers=headers, params=params)\n        response.raise_for_status()\n        content = response.json().get(\"content\")",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "save_file_locally",
        "kind": 2,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "def save_file_locally(file_path: str, content: str) -> bool:\n    \"\"\"ファイルをローカルに保存する\"\"\"\n    try:\n        # ディレクトリが存在しない場合は作成\n        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(content)\n        print(f\"ファイル保存成功: {file_path}\")\n        return True\n    except Exception as e:",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "get_json_diff",
        "kind": 2,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "def get_json_diff(\n    base_json: Dict[str, Any], target_json: Dict[str, Any]\n) -> Dict[str, Any]:\n    \"\"\"2つのJSONオブジェクト間の差分を計算する\"\"\"\n    base_keys = set(base_json.keys())\n    target_keys = set(target_json.keys())\n    added_keys = target_keys - base_keys\n    deleted_keys = base_keys - target_keys\n    common_keys = base_keys & target_keys\n    modified_keys = {",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "translate_text",
        "kind": 2,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "def translate_text(text: str, target_language: str, llm: ChatOpenAI) -> str:\n    \"\"\"指定されたテキストを翻訳する（JSONの値用）\"\"\"\n    if not isinstance(text, str) or not text.strip():\n        return text  # 文字列でない場合や空文字列はそのまま返す\n    # 翻訳結果のみを得るための洗練されたプロンプト\n    prompt = (\n        f\"Translate the following Japanese text to {target_language}. \"\n        \"Preserve any variables or placeholders like '{{variable}}' or '$t(key)' exactly as they appear. \"\n        \"Return ONLY the translation without any explanations, quotes, or additional text.\\n\\n\"\n        f'Text to translate: \"{text}\"'",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "translate_value",
        "kind": 2,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "def translate_value(value: Any, target_language: str, llm: ChatOpenAI) -> Any:\n    \"\"\"JSONの値（文字列、リスト、辞書）を再帰的に翻訳する\"\"\"\n    if isinstance(value, str):\n        return translate_text(value, target_language, llm)\n    elif isinstance(value, list):\n        return [translate_value(item, target_language, llm) for item in value]\n    elif isinstance(value, dict):\n        return {\n            key: translate_value(val, target_language, llm)\n            for key, val in value.items()",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "def main():\n    print(f\"ターゲットブランチ: {TARGET_BRANCH}\")\n    print(f\"ベースブランチ: {BASE_BRANCH}\")\n    # 1. ベースとターゲットの ja/translation.json を取得\n    print(f\"'{SOURCE_JSON_PATH}' を取得しています...\")\n    base_ja_content = get_file_content(SOURCE_JSON_PATH, BASE_BRANCH)\n    target_ja_content = get_file_content(SOURCE_JSON_PATH, TARGET_BRANCH)\n    if target_ja_content is None:\n        print(\n            f\"エラー: ターゲットブランチ '{TARGET_BRANCH}' に '{SOURCE_JSON_PATH}' が見つかりません。\"",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "GITHUB_API_BASE",
        "kind": 5,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "GITHUB_API_BASE = \"https://api.github.com\"\n# --- 環境変数読み込み ---\nGITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nTARGET_BRANCH = os.getenv(\"TARGET_BRANCH\")\nBASE_BRANCH = os.getenv(\"BASE_BRANCH\")\nREPO_FULL_NAME = os.getenv(\"REPO_FULL_NAME\")\n# --- 環境変数チェック ---\nif not GITHUB_TOKEN:\n    raise ValueError(\"環境変数 'GITHUB_TOKEN' が設定されていません。\")",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "GITHUB_TOKEN",
        "kind": 5,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nTARGET_BRANCH = os.getenv(\"TARGET_BRANCH\")\nBASE_BRANCH = os.getenv(\"BASE_BRANCH\")\nREPO_FULL_NAME = os.getenv(\"REPO_FULL_NAME\")\n# --- 環境変数チェック ---\nif not GITHUB_TOKEN:\n    raise ValueError(\"環境変数 'GITHUB_TOKEN' が設定されていません。\")\nif not OPENAI_API_KEY:\n    raise ValueError(\"環境変数 'OPENAI_API_KEY' が設定されていません。\")",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "OPENAI_API_KEY",
        "kind": 5,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nTARGET_BRANCH = os.getenv(\"TARGET_BRANCH\")\nBASE_BRANCH = os.getenv(\"BASE_BRANCH\")\nREPO_FULL_NAME = os.getenv(\"REPO_FULL_NAME\")\n# --- 環境変数チェック ---\nif not GITHUB_TOKEN:\n    raise ValueError(\"環境変数 'GITHUB_TOKEN' が設定されていません。\")\nif not OPENAI_API_KEY:\n    raise ValueError(\"環境変数 'OPENAI_API_KEY' が設定されていません。\")\nif not TARGET_BRANCH:",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "TARGET_BRANCH",
        "kind": 5,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "TARGET_BRANCH = os.getenv(\"TARGET_BRANCH\")\nBASE_BRANCH = os.getenv(\"BASE_BRANCH\")\nREPO_FULL_NAME = os.getenv(\"REPO_FULL_NAME\")\n# --- 環境変数チェック ---\nif not GITHUB_TOKEN:\n    raise ValueError(\"環境変数 'GITHUB_TOKEN' が設定されていません。\")\nif not OPENAI_API_KEY:\n    raise ValueError(\"環境変数 'OPENAI_API_KEY' が設定されていません。\")\nif not TARGET_BRANCH:\n    raise ValueError(\"環境変数 'TARGET_BRANCH' が設定されていません。\")",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "BASE_BRANCH",
        "kind": 5,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "BASE_BRANCH = os.getenv(\"BASE_BRANCH\")\nREPO_FULL_NAME = os.getenv(\"REPO_FULL_NAME\")\n# --- 環境変数チェック ---\nif not GITHUB_TOKEN:\n    raise ValueError(\"環境変数 'GITHUB_TOKEN' が設定されていません。\")\nif not OPENAI_API_KEY:\n    raise ValueError(\"環境変数 'OPENAI_API_KEY' が設定されていません。\")\nif not TARGET_BRANCH:\n    raise ValueError(\"環境変数 'TARGET_BRANCH' が設定されていません。\")\nif not BASE_BRANCH:",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "REPO_FULL_NAME",
        "kind": 5,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "REPO_FULL_NAME = os.getenv(\"REPO_FULL_NAME\")\n# --- 環境変数チェック ---\nif not GITHUB_TOKEN:\n    raise ValueError(\"環境変数 'GITHUB_TOKEN' が設定されていません。\")\nif not OPENAI_API_KEY:\n    raise ValueError(\"環境変数 'OPENAI_API_KEY' が設定されていません。\")\nif not TARGET_BRANCH:\n    raise ValueError(\"環境変数 'TARGET_BRANCH' が設定されていません。\")\nif not BASE_BRANCH:\n    raise ValueError(\"環境変数 'BASE_BRANCH' が設定されていません。\")",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "headers",
        "kind": 5,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "headers = {\n    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n    \"Accept\": \"application/vnd.github.v3+json\",\n}\n# 翻訳対象の言語リスト (日本語を除く)\nTARGET_LANGUAGES = [\n    \"en\",\n    \"zh\",\n    \"ko\",\n    \"vi\",",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "TARGET_LANGUAGES",
        "kind": 5,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "TARGET_LANGUAGES = [\n    \"en\",\n    \"zh\",\n    \"ko\",\n    \"vi\",\n    \"fr\",\n    \"es\",\n    \"pt\",\n    \"de\",\n    \"ru\",",
        "detail": "scripts.auto_translate",
        "documentation": {}
    },
    {
        "label": "SOURCE_JSON_PATH",
        "kind": 5,
        "importPath": "scripts.auto_translate",
        "description": "scripts.auto_translate",
        "peekOfCode": "SOURCE_JSON_PATH = \"locales/ja/translation.json\"\n# --- LLM ---\ndef get_llm():\n    \"\"\"LLMインスタンスを取得する\"\"\"\n    return ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0, api_key=OPENAI_API_KEY)\n# --- GitHub API 関数 ---\ndef get_file_content(file_path: str, ref: Optional[str] = None) -> Optional[str]:\n    \"\"\"指定されたファイルの内容を取得する\"\"\"\n    url = f\"{GITHUB_API_BASE}/repos/{REPO_FULL_NAME}/contents/{file_path}\"\n    params = {}",
        "detail": "scripts.auto_translate",
        "documentation": {}
    }
]